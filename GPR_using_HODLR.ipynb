{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6177134",
   "metadata": {},
   "source": [
    "# example.py in HODLR github"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf18b2d",
   "metadata": {},
   "source": [
    "# https://github.com/SAFRAN-LAB/HODLR/blob/master/python/example/example.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28b7ba87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000,)\n",
      "(1000, 1000)\n",
      "Error in Matrix-Matrix Multiplication: 2.2222603314940998e-14\n",
      "Error in Solve: 1.8242460117049233e-12\n",
      "Error in Log-Determinant Computation: 0.0\n",
      "Error in Symmetric Factor Multiplications: 2.212852270003981e-14\n",
      "Error in Getting Symmetric Factor: 2.48097312693929e-14\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pyhodlrlib\n",
    "\n",
    "# Size of the matrix:\n",
    "N = 1000\n",
    "x = np.sort(np.random.rand(N))\n",
    "print(x.shape)\n",
    "# Size of leaf level:\n",
    "M = 200\n",
    "\n",
    "# Returning the Gaussian Kernel:\n",
    "class Kernel(pyhodlrlib.HODLR_Matrix):\n",
    "    def getMatrixEntry(self, i, j):\n",
    "        if(i == j):\n",
    "            return 10\n",
    "        else:\n",
    "            return np.exp(-(x[i] - x[j])**2)\n",
    "\n",
    "K = Kernel(N)\n",
    "# What we are doing here is explicitly generating \n",
    "# the matrix from its entries\n",
    "A = K.getMatrix(0, 0, N, N)\n",
    "print(A.shape)\n",
    "# Tolerance for all factorizations:\n",
    "eps = 1e-12\n",
    "\n",
    "# If we are assembling a symmetric matrix:\n",
    "is_sym = True\n",
    "# If we know that the matrix is also PD:\n",
    "# By setting the matrix to be symmetric-positive definite, \n",
    "# we trigger the fast symmetric factorization method to be used\n",
    "# In all other cases the fast factorization method is used\n",
    "is_pd = True\n",
    "# Creating the HODLR object:\n",
    "T = pyhodlrlib.HODLR(N, M, eps)\n",
    "T.assemble(K, 'rookPivoting', is_sym, is_pd)\n",
    "\n",
    "# Random vector to take product with:\n",
    "x = np.random.rand(N)\n",
    "# Finding b using HODLR:\n",
    "b_hodlr = T.matmatProduct(x)\n",
    "# Finding b using direct MatVec:\n",
    "b = A @ x\n",
    "# Verifying the accuracy of the MatMat:\n",
    "print('Error in Matrix-Matrix Multiplication:', np.linalg.norm(b_hodlr.ravel() - b.ravel()) / np.linalg.norm(b))\n",
    "\n",
    "# Factorize elements of the tree:\n",
    "T.factorize()\n",
    "# Solving for x in A x = b:\n",
    "x_hodlr = T.solve(b)\n",
    "# Computing the relative error:\n",
    "print('Error in Solve:', np.linalg.norm(x_hodlr.ravel() - x) /  np.linalg.norm(x))\n",
    "\n",
    "# Finding log determinant:\n",
    "logdet_hodlr = T.logDeterminant()\n",
    "# Finding logdet:\n",
    "logdet = 2 * np.sum(np.log(abs(np.diag(np.linalg.cholesky(A)))))\n",
    "print('Error in Log-Determinant Computation:', abs(logdet_hodlr - logdet))\n",
    "\n",
    "# When system described is SPD:\n",
    "if(is_sym and is_pd):\n",
    "    # Setting y = W^T x\n",
    "    y = T.symmetricFactorTransposeProduct(x)\n",
    "    # Getting b = W (W^T x)\n",
    "    b_hodlr = T.symmetricFactorProduct(y)\n",
    "    print('Error in Symmetric Factor Multiplications:', np.linalg.norm(b_hodlr.ravel() - b.ravel()) / np.linalg.norm(b))\n",
    "\n",
    "    # Directly obtaining the symmetric factor matrix:\n",
    "    W = T.getSymmetricFactor()\n",
    "    print('Error in Getting Symmetric Factor:', np.mean(abs(W @ W.T - A)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae96fe4",
   "metadata": {},
   "source": [
    "# Code https://peterroelants.github.io/posts/gaussian-process-tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43a8c529",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import scipy\n",
    "from scipy.spatial import distance as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "445f55f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the exponentiated quadratic \n",
    "def exponentiated_quadratic(xa, xb):\n",
    "    \"\"\"Exponentiated quadratic  with σ=1\"\"\"\n",
    "    # L2 distance (Squared Euclidian)\n",
    "    sq_norm = -0.5 * scipy.spatial.distance.cdist(xa, xb, 'sqeuclidean')\n",
    "    return np.exp(sq_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32fad3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian process posterior\n",
    "def GP(X1, y1, X2, kernel_func):\n",
    "    \"\"\"\n",
    "    Calculate the posterior mean and covariance matrix for y2\n",
    "    based on the corresponding input X2, the observations (y1, X1), \n",
    "    and the prior kernel function.\n",
    "    \"\"\"\n",
    "    # Kernel of the observations\n",
    "    Σ11 = kernel_func(X1, X1)\n",
    "    # Kernel of observations vs to-predict\n",
    "    Σ12 = kernel_func(X1, X2)\n",
    "    # Solve\n",
    "    solved = scipy.linalg.solve(Σ11, Σ12, assume_a='pos').T\n",
    "    # Compute posterior mean\n",
    "    μ2 = solved @ y1\n",
    "    # Compute the posterior covariance\n",
    "    Σ22 = kernel_func(X2, X2)\n",
    "    Σ2 = Σ22 - (solved @ Σ12)\n",
    "    return μ2, Σ2  # mean, covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c83b50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the posterior mean and covariance\n",
    "\n",
    "# Define the true function that we want to regress on\n",
    "f_sin = lambda x: (np.sin(x)).flatten()\n",
    "\n",
    "n1 = 8  # Number of points to condition on (training points)\n",
    "n2 = 75  # Number of points in posterior (test points)\n",
    "ny = 5  # Number of functions that will be sampled from the posterior\n",
    "domain = (-6, 6)\n",
    "\n",
    "# Sample observations (X1, y1) on the function\n",
    "X1 = np.random.uniform(domain[0]+2, domain[1]-2, size=(n1, 1))\n",
    "y1 = f_sin(X1)\n",
    "# Predict points at uniform spacing to capture function\n",
    "X2 = np.linspace(domain[0], domain[1], n2).reshape(-1, 1)\n",
    "# Compute posterior mean and covariance\n",
    "μ2, Σ2 = GP(X1, y1, X2, exponentiated_quadratic)\n",
    "# Compute the standard deviation at the test points to be plotted\n",
    "σ2 = np.sqrt(np.diag(Σ2))\n",
    "\n",
    "# Draw some samples of the posterior\n",
    "y2 = np.random.multivariate_normal(mean=μ2, cov=Σ2, size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49457640",
   "metadata": {},
   "source": [
    "# code gpr by changing the function getMatrixEntry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b82c6921",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy.spatial import distance as dist\n",
    "class Kernel(pyhodlrlib.HODLR_Matrix):\n",
    "    def getMatrixEntry(self, X, Y):\n",
    "        \n",
    "        sq=-0.5*dist.cdist(X, Y, 'sqeuclidean')\n",
    "        return np.exp(sq)\n",
    "    def GP_hod(self,X1, y1, X2):\n",
    "        \"\"\"\n",
    "        Calculate the posterior mean and covariance matrix for y2\n",
    "        based on the corresponding input X2, the observations (y1, X1), \n",
    "        and the prior kernel function.\n",
    "        \"\"\"\n",
    "        K = Kernel(N1)\n",
    "        # What we are doing here is explicitly generating \n",
    "        # the matrix from its entries\n",
    "        A11=K.getMatrixEntry(X1,X1)\n",
    "        #print(A11,\"A11\")\n",
    "       \n",
    "        # Tolerance for all factorizations:\n",
    "        eps = 1e-12\n",
    "\n",
    "        # If we are assembling a symmetric matrix:\n",
    "        is_sym = True\n",
    "        # If we know that the matrix is also PD:\n",
    "        # By setting the matrix to be symmetric-positive definite, \n",
    "        # we trigger the fast symmetric factorization method to be used\n",
    "        # In all other cases the fast factorization method is used\n",
    "        is_pd = True\n",
    "        \n",
    "        # Creating the HODLR object:\n",
    "        \n",
    "        #M=3\n",
    "        #T = pyhodlrlib.HODLR(N1, M, eps)\n",
    "        #T.assemble(K, 'rookPivoting', is_sym, is_pd)\n",
    "\n",
    "        #Σ12 = kernel_func(X1, X2)\n",
    "        # Solve\n",
    "        A12=K.getMatrixEntry(X1,X2)\n",
    "        \n",
    "        solved = scipy.linalg.solve(A11, A12, assume_a='pos').T\n",
    "        # Compute posterior mean\n",
    "        μ2 = solved @ y1\n",
    "        \n",
    "        \n",
    "        A22=K.getMatrixEntry(X2,X2)\n",
    "        \n",
    "        # Compute the posterior covariance\n",
    "        Σ2 = A22 - (solved @ A12)\n",
    "        #print(\"A11 shape\",A11.shape)\n",
    "        #print(\"A12 shape\",A12.shape)\n",
    "        #print(\"A22 shape\",A22.shape)\n",
    "        return μ2, Σ2  # mean, covariance\n",
    "    # Gaussian process posterior\n",
    "    def GP(self,X1, y1, X2, kernel_func):\n",
    "        \"\"\"\n",
    "        Calculate the posterior mean and covariance matrix for y2\n",
    "        based on the corresponding input X2, the observations (y1, X1), \n",
    "        and the prior kernel function.\n",
    "        \"\"\"\n",
    "        # Kernel of the observations\n",
    "        Σ11 = kernel_func(X1, X1)\n",
    "        # Kernel of observations vs to-predict\n",
    "        Σ12 = kernel_func(X1, X2)\n",
    "        # Solve\n",
    "        solved = scipy.linalg.solve(Σ11, Σ12, assume_a='pos').T\n",
    "       \n",
    "        # Compute posterior mean\n",
    "        μ2 = solved @ y1\n",
    "\n",
    "        # Compute the posterior covariance\n",
    "        Σ22 = kernel_func(X2, X2)\n",
    "        \n",
    "        Σ2 = Σ22 - (solved @ Σ12)\n",
    "\n",
    "        return μ2, Σ2  # mean, covariance\n",
    "# Define the exponentiated quadratic \n",
    "def exponentiated_quadratic(xa, xb):\n",
    "    \"\"\"Exponentiated quadratic  with σ=1\"\"\"\n",
    "    # L2 distance (Squared Euclidian)\n",
    "    sq_norm = -0.5 * dist.cdist(xa, xb, 'sqeuclidean')\n",
    "    return np.exp(sq_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3b1cbbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 1)\n",
      "[ 0.05573094 -0.03823085  0.1054012   0.01069035 -0.01792854] [[ 9.94545164e-01 -3.81718181e-02  1.21803989e-03 -1.15555062e-04\n",
      "   9.29957520e-06]\n",
      " [-3.81718181e-02  2.10338804e-01 -2.66793506e-02  2.74488515e-03\n",
      "  -2.21347940e-04]\n",
      " [ 1.21803989e-03 -2.66793506e-02  7.11846602e-02 -2.33326049e-02\n",
      "   2.10988712e-03]\n",
      " [-1.15555062e-04  2.74488515e-03 -2.33326049e-02  4.93259306e-02\n",
      "  -1.51539673e-02]\n",
      " [ 9.29957520e-06 -2.21347940e-04  2.10988712e-03 -1.51539673e-02\n",
      "   9.98600826e-01]]\n",
      "******\n",
      "[ 0.05573094 -0.03823085  0.1054012   0.01069035 -0.01792854] [[ 9.94545164e-01 -3.81718181e-02  1.21803989e-03 -1.15555062e-04\n",
      "   9.29957520e-06]\n",
      " [-3.81718181e-02  2.10338804e-01 -2.66793506e-02  2.74488515e-03\n",
      "  -2.21347940e-04]\n",
      " [ 1.21803989e-03 -2.66793506e-02  7.11846602e-02 -2.33326049e-02\n",
      "   2.10988712e-03]\n",
      " [-1.15555062e-04  2.74488515e-03 -2.33326049e-02  4.93259306e-02\n",
      "  -1.51539673e-02]\n",
      " [ 9.29957520e-06 -2.21347940e-04  2.10988712e-03 -1.51539673e-02\n",
      "   9.98600826e-01]]\n"
     ]
    }
   ],
   "source": [
    "# Compute the posterior mean and covariance\n",
    "\n",
    "# Define the true function that we want to regress on\n",
    "f_sin = lambda x: (np.sin(x)).flatten()\n",
    "\n",
    "N1 = 6  # Number of points to condition on (training points)\n",
    "N2 = 5  # Number of points in posterior (test points)\n",
    "ny = 5  # Number of functions that will be sampled from the posterior\n",
    "domain = (-6, 6)\n",
    "\n",
    "# Sample observations (X1, y1) on the function\n",
    "X1 = np.random.uniform(domain[0]+2, domain[1]-2, size=(N1, 1))\n",
    "print(X1.shape)\n",
    "y1 = f_sin(X1)\n",
    "# Predict points at uniform spacing to capture function\n",
    "X2 = np.linspace(domain[0], domain[1], N2).reshape(-1, 1)\n",
    "# Compute posterior mean and covariance\n",
    "K = Kernel(N1)\n",
    "μ2_hod, Σ2_hod = K.GP_hod(X1, y1, X2)\n",
    "print(μ2_hod, Σ2_hod)\n",
    "print(\"******\")\n",
    "μ2, Σ2 = K.GP(X1, y1, X2,exponentiated_quadratic)\n",
    "print(μ2, Σ2)\n",
    "#print(Σ2.shape)\n",
    "# Compute the standard deviation at the test points to be plotted\n",
    "σ2 = np.sqrt(np.diag(Σ2))\n",
    "σ2_hod = np.sqrt(np.diag(Σ2_hod))\n",
    "\n",
    "# Draw some samples of the posterior\n",
    "y2 = np.random.multivariate_normal(mean=μ2, cov=Σ2, size=1)\n",
    "y2_hod = np.random.multivariate_normal(mean=μ2_hod, cov=Σ2_hod, size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b052e24b",
   "metadata": {},
   "source": [
    "# Gpr using HODLR properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12cf7a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian process posterior\n",
    "# Returning the Gaussian Kernel:\n",
    "import scipy\n",
    "from scipy.spatial import distance as dist\n",
    "class Kernel1(pyhodlrlib.HODLR_Matrix):\n",
    "    def getMatrixEntry(self, i, j):\n",
    "         return np.exp(-(X1[i] - X1[j])**2)\n",
    "    def GP_hod(self,X1, y1, X2):\n",
    "        # What we are doing here is explicitly generating \n",
    "        # the matrix from its entries\n",
    "        A11=K1.getMatrix(0,0,N1,N1)\n",
    "        #print(A11,\"A11\")\n",
    "        return A11\n",
    "class Kernel2(pyhodlrlib.HODLR_Matrix):\n",
    "    def getMatrixEntry(self, i, j):\n",
    "         return np.exp(-(X1[i] - X2[j])**2)\n",
    "    def GP_hod(self,X1, y1, X2):\n",
    "       \n",
    "        # the matrix from its entries\n",
    "        A12=K2.getMatrix(0,0,N1,N2)\n",
    "        #print(A12,\"A12\")\n",
    "        \n",
    "        return A12\n",
    "class Kernel3(pyhodlrlib.HODLR_Matrix):\n",
    "    def getMatrixEntry(self, i, j):\n",
    "         return np.exp(-(X2[i] - X2[j])**2)\n",
    "    def GP_hod(self,X1, y1, X2):\n",
    "        \n",
    "        # the matrix from its entries\n",
    "        A22=K3.getMatrix(0,0,N2,N2)\n",
    "        #print(A22,\"A22\")\n",
    "\n",
    "        return A22\n",
    "# Define the exponentiated quadratic \n",
    "def exponentiated_quadratic(xa, xb):\n",
    "    \"\"\"Exponentiated quadratic  with σ=1\"\"\"\n",
    "    # L2 distance (Squared Euclidian)\n",
    "    sq_norm = -0.5 * dist.cdist(xa, xb, 'sqeuclidean')\n",
    "    return np.exp(sq_norm)\n",
    " # Gaussian process posterior\n",
    "def GP(X1, y1, X2, kernel_func):\n",
    "    \"\"\"\n",
    "    Calculate the posterior mean and covariance matrix for y2\n",
    "    based on the corresponding input X2, the observations (y1, X1), \n",
    "    and the prior kernel function.\n",
    "    \"\"\"\n",
    "    # Kernel of the observations\n",
    "    Σ11 = kernel_func(X1, X1)\n",
    "    # Kernel of observations vs to-predict\n",
    "    Σ12 = kernel_func(X1, X2)\n",
    "    # Solve\n",
    "    solved = scipy.linalg.solve(Σ11, Σ12, assume_a='pos').T\n",
    "    print(\"*****\")\n",
    "    print(\"splved\",solved)\n",
    "    # Compute posterior mean\n",
    "    μ2 = solved @ y1\n",
    "\n",
    "    # Compute the posterior covariance\n",
    "    Σ22 = kernel_func(X2, X2)\n",
    "    Σ2 = Σ22 - (solved @ Σ12)\n",
    "\n",
    "    return μ2, Σ2  # mean, covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be413886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 1)\n",
      "22 [-1.85981932e-06 -2.99862641e-01 -4.24386088e-02 -2.85644676e-01\n",
      " -2.53423962e-03] [[ 1.00000000e+00  1.14030332e-04  5.80348949e-07 -8.04957694e-09\n",
      "   2.12595993e-12]\n",
      " [ 1.14030332e-04  1.81702809e-01  1.87155642e-02 -2.68008607e-04\n",
      "   7.07844638e-08]\n",
      " [ 5.80348949e-07  1.87155642e-02  7.68102283e-02 -4.31679155e-03\n",
      "   1.15435664e-06]\n",
      " [-8.04957694e-09 -2.68008607e-04 -4.31679155e-03  6.13457644e-01\n",
      "  -2.87574981e-03]\n",
      " [ 2.12595993e-12  7.07844638e-08  1.15435664e-06 -2.87574981e-03\n",
      "   9.99976626e-01]] 22\n",
      "******\n",
      "*****\n",
      "splved [[ 1.51272302e-02  5.14897542e-02 -6.01228935e-02 -4.08226681e-05\n",
      "  -3.66599740e-03  9.12006910e-04]\n",
      " [ 1.65142483e+00  2.38412548e+00 -3.02257451e+00 -1.38136336e-03\n",
      "  -1.30664246e-01  3.09173144e-02]\n",
      " [-1.36018299e-01 -1.22009258e+00  1.16669560e+00 -4.73767762e-03\n",
      "   1.07819470e+00  1.15293086e-01]\n",
      " [ 5.89477454e-02  4.46038939e-01 -4.46789286e-01  7.78328080e-01\n",
      "  -1.13122257e-01  2.02001484e-01]\n",
      " [-1.24089704e-03 -9.35867272e-03  9.38208854e-03  6.97153298e-02\n",
      "   2.34870139e-03 -3.96510203e-03]]\n",
      "11 [ 0.00119812 -0.24333876  0.0016987  -0.22891315 -0.03986488] [[ 9.99962226e-01  6.72553491e-03  3.03506186e-04 -1.34324070e-04\n",
      "   2.82881965e-06]\n",
      " [ 6.72553491e-03  3.85882451e-02  8.92713795e-03 -4.52920200e-03\n",
      "   9.57214314e-05]\n",
      " [ 3.03506186e-04  8.92713795e-03  1.10412680e-02 -1.42058694e-02\n",
      "   3.28208561e-04]\n",
      " [-1.34324070e-04 -4.52920200e-03 -1.42058694e-02  3.46545933e-01\n",
      "  -4.30118168e-02]\n",
      " [ 2.82881965e-06  9.57214314e-05  3.28208561e-04 -4.30118168e-02\n",
      "   9.95152599e-01]] 11\n"
     ]
    }
   ],
   "source": [
    "# Compute the posterior mean and covariance\n",
    "\n",
    "# Define the true function that we want to regress on\n",
    "f_sin = lambda x: (np.sin(x)).flatten()\n",
    "\n",
    "N1 = 6  # Number of points to condition on (training points)\n",
    "N2 = 5  # Number of points in posterior (test points)\n",
    "#ny = 5  # Number of functions that will be sampled from the posterior\n",
    "domain = (-6, 6)\n",
    "\n",
    "# Sample observations (X1, y1) on the function\n",
    "X1 = np.random.uniform(domain[0]+2, domain[1]-2, size=(N1, 1))\n",
    "y1 = f_sin(X1)\n",
    "# Predict points at uniform spacing to capture function\n",
    "X2 = np.linspace(domain[0], domain[1], N2).reshape(-1, 1)\n",
    "print(X2.shape)\n",
    "y2_act=f_sin(X2)\n",
    "# Compute posterior mean and covariance\n",
    "K1 = Kernel1(N1)\n",
    "A11 = K1.GP_hod(X1, y1, X2)\n",
    "K2 = Kernel2(N1)\n",
    "A12 = K2.GP_hod(X1, y1, X2)\n",
    "K3 = Kernel3(N2)\n",
    "A22 = K3.GP_hod(X1, y1, X2)\n",
    "eps = 1e-12\n",
    "# If we are assembling a symmetric matrix:\n",
    "is_sym = True\n",
    "# If we know that the matrix is also PD:\n",
    "# By setting the matrix to be symmetric-positive definite, \n",
    "# we trigger the fast symmetric factorization method to be used\n",
    "# In all other cases the fast factorization method is used\n",
    "is_pd = True\n",
    "# Creating the HODLR object:\n",
    "#print(type(A11))\n",
    "M=3\n",
    "T = pyhodlrlib.HODLR(N1, M, eps)\n",
    "T.assemble(K1, 'rookPivoting', is_sym, is_pd)\n",
    "# Factorize elements of the tree:\n",
    "T.factorize()\n",
    "# Solving for x in A x = b:\n",
    "x_hodlr = T.solve(A12)\n",
    "x_hodlr=x_hodlr.T\n",
    "# Compute posterior mean\n",
    "#print(x_hodlr.shape,y1.shape,A12.shape,A22.shape)\n",
    "μ2_hod = x_hodlr @ y1\n",
    "Σ2_hod = A22 - (x_hodlr @ A12)\n",
    "print(\"22\",μ2_hod, Σ2_hod,\"22\")\n",
    "print(\"******\")\n",
    "μ2, Σ2 = GP(X1, y1, X2,exponentiated_quadratic)\n",
    "print(\"11\",μ2, Σ2,\"11\")\n",
    "# Compute the standard deviation at the test points to be plotted\n",
    "σ2 = np.sqrt(np.diag(Σ2))\n",
    "σ2_hod = np.sqrt(np.diag(Σ2_hod))\n",
    "\n",
    "# Draw some samples of the posterior\n",
    "y2 = np.random.multivariate_normal(mean=μ2, cov=Σ2, size=1)\n",
    "y2_hod = np.random.multivariate_normal(mean=μ2_hod, cov=Σ2_hod, size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b988f43e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.12930635, -0.06712564, -0.46085581,  0.1889964 , -0.35303797])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5b980487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.18604743,  0.01075804,  1.31618782,  0.53153043, -0.34720879])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2_hod[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cfee0a6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.2794155 , -0.14112001,  0.        ,  0.14112001, -0.2794155 ])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y2_act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "404fe3e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.03577798e-09, -2.54642497e-05,  2.01713344e-08,\n",
       "         6.52278081e-05, -1.38124279e-08, -9.92893477e-10],\n",
       "       [ 4.11122988e-06, -1.01786662e-01,  8.00717712e-05,\n",
       "         1.02279311e+00, -5.48249143e-05, -3.94101166e-06],\n",
       "       [ 2.97201636e-02,  3.14437305e-02,  7.34448243e-01,\n",
       "        -1.20337228e-02, -4.03840130e-01, -2.84850523e-02],\n",
       "       [ 4.34973173e+00,  5.02301966e-05, -1.06560576e-01,\n",
       "        -1.95711344e-05,  1.68965012e-01, -3.89224749e+00],\n",
       "       [-2.44653194e-01,  2.02870160e-07, -4.29343478e-04,\n",
       "        -7.90445885e-08,  6.40178015e-04,  2.56440808e-01]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_hodlr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "88f9f498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE score is 1185516592564450.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "mape = mean_absolute_percentage_error(y2_act,y2_hod[0])\n",
    "print('MAPE score is {}'.format(mape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "42e09d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE score is 415102010526475.7\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "mape = mean_absolute_percentage_error(y2_act,y2[0])\n",
    "print('MAPE score is {}'.format(mape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd41855",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
