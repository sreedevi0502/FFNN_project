{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6177134",
   "metadata": {},
   "source": [
    "# example.py in HODLR github"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf18b2d",
   "metadata": {},
   "source": [
    "# https://github.com/SAFRAN-LAB/HODLR/blob/master/python/example/example.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28b7ba87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000,)\n",
      "(1000, 1000)\n",
      "Error in Matrix-Matrix Multiplication: 2.5428764967620053e-14\n",
      "(1000, 1) (1000,)\n",
      "Error in Solve: 2.0762204025187137e-12\n",
      "Error in Log-Determinant Computation: 9.094947017729282e-13\n",
      "Error in Symmetric Factor Multiplications: 2.5366937452397554e-14\n",
      "Error in Getting Symmetric Factor: 2.6573587663669685e-14\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pyhodlrlib\n",
    "\n",
    "# Size of the matrix:\n",
    "N = 1000\n",
    "x = np.sort(np.random.rand(N))\n",
    "print(x.shape)\n",
    "# Size of leaf level:\n",
    "M = 200\n",
    "\n",
    "# Returning the Gaussian Kernel:\n",
    "class Kernel(pyhodlrlib.HODLR_Matrix):\n",
    "    def getMatrixEntry(self, i, j):\n",
    "        if(i == j):\n",
    "            return 10\n",
    "        else:\n",
    "            return np.exp(-(x[i] - x[j])**2)\n",
    "\n",
    "K = Kernel(N)\n",
    "# What we are doing here is explicitly generating \n",
    "# the matrix from its entries\n",
    "A = K.getMatrix(0, 0, N, N)\n",
    "print(A.shape)\n",
    "# Tolerance for all factorizations:\n",
    "eps = 1e-12\n",
    "\n",
    "# If we are assembling a symmetric matrix:\n",
    "is_sym = True\n",
    "# If we know that the matrix is also PD:\n",
    "# By setting the matrix to be symmetric-positive definite, \n",
    "# we trigger the fast symmetric factorization method to be used\n",
    "# In all other cases the fast factorization method is used\n",
    "is_pd = True\n",
    "# Creating the HODLR object:\n",
    "T = pyhodlrlib.HODLR(N, M, eps)\n",
    "T.assemble(K, 'rookPivoting', is_sym, is_pd)\n",
    "\n",
    "# Random vector to take product with:\n",
    "x = np.random.rand(N)\n",
    "# Finding b using HODLR:\n",
    "b_hodlr = T.matmatProduct(x)\n",
    "# Finding b using direct MatVec:\n",
    "b = A @ x\n",
    "# Verifying the accuracy of the MatMat:\n",
    "print('Error in Matrix-Matrix Multiplication:', np.linalg.norm(b_hodlr.ravel() - b.ravel()) / np.linalg.norm(b))\n",
    "\n",
    "# Factorize elements of the tree:\n",
    "T.factorize()\n",
    "# Solving for x in A x = b:\n",
    "x_hodlr = T.solve(b)\n",
    "print(x_hodlr.shape,b.shape)\n",
    "# Computing the relative error:\n",
    "print('Error in Solve:', np.linalg.norm(x_hodlr.ravel() - x) /  np.linalg.norm(x))\n",
    "\n",
    "# Finding log determinant:\n",
    "logdet_hodlr = T.logDeterminant()\n",
    "# Finding logdet:\n",
    "logdet = 2 * np.sum(np.log(abs(np.diag(np.linalg.cholesky(A)))))\n",
    "print('Error in Log-Determinant Computation:', abs(logdet_hodlr - logdet))\n",
    "\n",
    "# When system described is SPD:\n",
    "if(is_sym and is_pd):\n",
    "    # Setting y = W^T x\n",
    "    y = T.symmetricFactorTransposeProduct(x)\n",
    "    # Getting b = W (W^T x)\n",
    "    b_hodlr = T.symmetricFactorProduct(y)\n",
    "    print('Error in Symmetric Factor Multiplications:', np.linalg.norm(b_hodlr.ravel() - b.ravel()) / np.linalg.norm(b))\n",
    "\n",
    "    # Directly obtaining the symmetric factor matrix:\n",
    "    W = T.getSymmetricFactor()\n",
    "    print('Error in Getting Symmetric Factor:', np.mean(abs(W @ W.T - A)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae96fe4",
   "metadata": {},
   "source": [
    "# Code https://peterroelants.github.io/posts/gaussian-process-tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43a8c529",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import scipy\n",
    "from scipy.spatial import distance as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "445f55f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the exponentiated quadratic \n",
    "def exponentiated_quadratic(xa, xb):\n",
    "    \"\"\"Exponentiated quadratic  with σ=1\"\"\"\n",
    "    # L2 distance (Squared Euclidian)\n",
    "    sq_norm = -0.5 * scipy.spatial.distance.cdist(xa, xb, 'sqeuclidean')\n",
    "    return np.exp(sq_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32fad3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian process posterior\n",
    "def GP(X1, y1, X2, kernel_func):\n",
    "    \"\"\"\n",
    "    Calculate the posterior mean and covariance matrix for y2\n",
    "    based on the corresponding input X2, the observations (y1, X1), \n",
    "    and the prior kernel function.\n",
    "    \"\"\"\n",
    "    # Kernel of the observations\n",
    "    Σ11 = kernel_func(X1, X1)\n",
    "    # Kernel of observations vs to-predict\n",
    "    Σ12 = kernel_func(X1, X2)\n",
    "    # Solve\n",
    "    solved = scipy.linalg.solve(Σ11, Σ12, assume_a='pos').T\n",
    "    # Compute posterior mean\n",
    "    μ2 = solved @ y1\n",
    "    # Compute the posterior covariance\n",
    "    Σ22 = kernel_func(X2, X2)\n",
    "    Σ2 = Σ22 - (solved @ Σ12)\n",
    "    return μ2, Σ2  # mean, covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c83b50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the posterior mean and covariance\n",
    "\n",
    "# Define the true function that we want to regress on\n",
    "f_sin = lambda x: (np.sin(x)).flatten()\n",
    "\n",
    "n1 = 8  # Number of points to condition on (training points)\n",
    "n2 = 75  # Number of points in posterior (test points)\n",
    "ny = 5  # Number of functions that will be sampled from the posterior\n",
    "domain = (-6, 6)\n",
    "\n",
    "# Sample observations (X1, y1) on the function\n",
    "X1 = np.random.uniform(domain[0]+2, domain[1]-2, size=(n1, 1))\n",
    "y1 = f_sin(X1)\n",
    "# Predict points at uniform spacing to capture function\n",
    "X2 = np.linspace(domain[0], domain[1], n2).reshape(-1, 1)\n",
    "# Compute posterior mean and covariance\n",
    "μ2, Σ2 = GP(X1, y1, X2, exponentiated_quadratic)\n",
    "# Compute the standard deviation at the test points to be plotted\n",
    "σ2 = np.sqrt(np.diag(Σ2))\n",
    "\n",
    "# Draw some samples of the posterior\n",
    "y2 = np.random.multivariate_normal(mean=μ2, cov=Σ2, size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49457640",
   "metadata": {},
   "source": [
    "# code gpr by changing the function getMatrixEntry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b82c6921",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy.spatial import distance as dist\n",
    "class Kernel(pyhodlrlib.HODLR_Matrix):\n",
    "    def getMatrixEntry(self, X, Y):\n",
    "        \n",
    "        sq=-0.5*dist.cdist(X, Y, 'sqeuclidean')\n",
    "        return np.exp(sq)\n",
    "    def GP_hod(self,X1, y1, X2):\n",
    "        \"\"\"\n",
    "        Calculate the posterior mean and covariance matrix for y2\n",
    "        based on the corresponding input X2, the observations (y1, X1), \n",
    "        and the prior kernel function.\n",
    "        \"\"\"\n",
    "        K = Kernel(N1)\n",
    "        # What we are doing here is explicitly generating \n",
    "        # the matrix from its entries\n",
    "        A11=K.getMatrixEntry(X1,X1)\n",
    "        #print(A11,\"A11\")\n",
    "       \n",
    "        # Tolerance for all factorizations:\n",
    "        eps = 1e-12\n",
    "\n",
    "        # If we are assembling a symmetric matrix:\n",
    "        is_sym = True\n",
    "        # If we know that the matrix is also PD:\n",
    "        # By setting the matrix to be symmetric-positive definite, \n",
    "        # we trigger the fast symmetric factorization method to be used\n",
    "        # In all other cases the fast factorization method is used\n",
    "        is_pd = True\n",
    "        \n",
    "        # Creating the HODLR object:\n",
    "        \n",
    "        #M=3\n",
    "        #T = pyhodlrlib.HODLR(N1, M, eps)\n",
    "        #T.assemble(K, 'rookPivoting', is_sym, is_pd)\n",
    "\n",
    "        #Σ12 = kernel_func(X1, X2)\n",
    "        # Solve\n",
    "        A12=K.getMatrixEntry(X1,X2)\n",
    "        \n",
    "        solved = scipy.linalg.solve(A11, A12, assume_a='pos').T\n",
    "        # Compute posterior mean\n",
    "        μ2 = solved @ y1\n",
    "        \n",
    "        \n",
    "        A22=K.getMatrixEntry(X2,X2)\n",
    "        \n",
    "        # Compute the posterior covariance\n",
    "        Σ2 = A22 - (solved @ A12)\n",
    "        #print(\"A11 shape\",A11.shape)\n",
    "        #print(\"A12 shape\",A12.shape)\n",
    "        #print(\"A22 shape\",A22.shape)\n",
    "        return μ2, Σ2  # mean, covariance\n",
    "    # Gaussian process posterior\n",
    "    def GP(self,X1, y1, X2, kernel_func):\n",
    "        \"\"\"\n",
    "        Calculate the posterior mean and covariance matrix for y2\n",
    "        based on the corresponding input X2, the observations (y1, X1), \n",
    "        and the prior kernel function.\n",
    "        \"\"\"\n",
    "        # Kernel of the observations\n",
    "        Σ11 = kernel_func(X1, X1)\n",
    "        print(\"Σ11\",Σ11)\n",
    "        # Kernel of observations vs to-predict\n",
    "        Σ12 = kernel_func(X1, X2)\n",
    "        # Solve\n",
    "        solved = scipy.linalg.solve(Σ11, Σ12, assume_a='pos').T\n",
    "       \n",
    "        # Compute posterior mean\n",
    "        μ2 = solved @ y1\n",
    "\n",
    "        # Compute the posterior covariance\n",
    "        Σ22 = kernel_func(X2, X2)\n",
    "        \n",
    "        Σ2 = Σ22 - (solved @ Σ12)\n",
    "\n",
    "        return μ2, Σ2  # mean, covariance\n",
    "# Define the exponentiated quadratic \n",
    "def exponentiated_quadratic(xa, xb):\n",
    "    \"\"\"Exponentiated quadratic  with σ=1\"\"\"\n",
    "    # L2 distance (Squared Euclidian)\n",
    "    sq_norm = -0.5 * dist.cdist(xa, xb, 'sqeuclidean')\n",
    "    return np.exp(sq_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3b1cbbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 1)\n",
      "[-7.85736563e-06 -1.91405856e-01  2.46592580e-02  1.42348404e-01\n",
      " -1.13202298e-01] [[1.00000000e+00 1.11069324e-02 1.48201468e-06 4.77285645e-09\n",
      "  8.46664501e-08]\n",
      " [1.11069324e-02 9.52127545e-01 2.43234995e-02 9.39059325e-05\n",
      "  1.67273822e-03]\n",
      " [1.48201468e-06 2.43234995e-02 1.96002712e-02 2.06722188e-04\n",
      "  4.08941114e-03]\n",
      " [4.77285645e-09 9.39059325e-05 2.06722188e-04 1.26966043e-05\n",
      "  6.44446029e-04]\n",
      " [8.46664501e-08 1.67273822e-03 4.08941114e-03 6.44446029e-04\n",
      "  9.75889108e-01]]\n",
      "******\n",
      "[-7.85736563e-06 -1.91405856e-01  2.46592580e-02  1.42348404e-01\n",
      " -1.13202298e-01] [[1.00000000e+00 1.11069324e-02 1.48201468e-06 4.77285645e-09\n",
      "  8.46664501e-08]\n",
      " [1.11069324e-02 9.52127545e-01 2.43234995e-02 9.39059325e-05\n",
      "  1.67273822e-03]\n",
      " [1.48201468e-06 2.43234995e-02 1.96002712e-02 2.06722188e-04\n",
      "  4.08941114e-03]\n",
      " [4.77285645e-09 9.39059325e-05 2.06722188e-04 1.26966043e-05\n",
      "  6.44446029e-04]\n",
      " [8.46664501e-08 1.67273822e-03 4.08941114e-03 6.44446029e-04\n",
      "  9.75889108e-01]]\n"
     ]
    }
   ],
   "source": [
    "# Compute the posterior mean and covariance\n",
    "\n",
    "# Define the true function that we want to regress on\n",
    "f_sin = lambda x: (np.sin(x)).flatten()\n",
    "\n",
    "N1 = 6  # Number of points to condition on (training points)\n",
    "N2 = 5  # Number of points in posterior (test points)\n",
    "ny = 5  # Number of functions that will be sampled from the posterior\n",
    "domain = (-6, 6)\n",
    "\n",
    "# Sample observations (X1, y1) on the function\n",
    "X1 = np.random.uniform(domain[0]+2, domain[1]-2, size=(N1, 1))\n",
    "print(X1.shape)\n",
    "y1 = f_sin(X1)\n",
    "# Predict points at uniform spacing to capture function\n",
    "X2 = np.linspace(domain[0], domain[1], N2).reshape(-1, 1)\n",
    "# Compute posterior mean and covariance\n",
    "K = Kernel(N1)\n",
    "μ2_hod, Σ2_hod = K.GP_hod(X1, y1, X2)\n",
    "print(μ2_hod, Σ2_hod)\n",
    "print(\"******\")\n",
    "μ2, Σ2 = K.GP(X1, y1, X2,exponentiated_quadratic)\n",
    "print(μ2, Σ2)\n",
    "#print(Σ2.shape)\n",
    "# Compute the standard deviation at the test points to be plotted\n",
    "σ2 = np.sqrt(np.diag(Σ2))\n",
    "σ2_hod = np.sqrt(np.diag(Σ2_hod))\n",
    "\n",
    "# Draw some samples of the posterior\n",
    "y2 = np.random.multivariate_normal(mean=μ2, cov=Σ2, size=1)\n",
    "y2_hod = np.random.multivariate_normal(mean=μ2_hod, cov=Σ2_hod, size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b052e24b",
   "metadata": {},
   "source": [
    "# Gpr using HODLR properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30b4426e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyhodlrlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "12cf7a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian process posterior\n",
    "# Returning the Gaussian Kernel:\n",
    "import scipy\n",
    "from scipy.spatial import distance as dist\n",
    "class Kernel1(pyhodlrlib.HODLR_Matrix):\n",
    "    def getMatrixEntry(self, i, j):\n",
    "         return np.exp(-0.5*(X1[i] - X1[j])**2)\n",
    "    def GP_hod(self,X1, y1, X2):\n",
    "        # What we are doing here is explicitly generating \n",
    "        # the matrix from its entries\n",
    "        A11=K1.getMatrix(0,0,N1,N1)\n",
    "        #print(A11,\"A11\")\n",
    "        return A11\n",
    "class Kernel2(pyhodlrlib.HODLR_Matrix):\n",
    "    def getMatrixEntry(self, i, j):\n",
    "         return np.exp(-0.5*(X1[i] - X2[j])**2)\n",
    "    def GP_hod(self,X1, y1, X2):\n",
    "       \n",
    "        # the matrix from its entries\n",
    "        A12=K2.getMatrix(0,0,N1,N2)\n",
    "        #print(A12,\"A12\")\n",
    "        \n",
    "        return A12\n",
    "class Kernel3(pyhodlrlib.HODLR_Matrix):\n",
    "    def getMatrixEntry(self, i, j):\n",
    "         return np.exp(-0.5*(X2[i] - X2[j])**2)\n",
    "    def GP_hod(self,X1, y1, X2):\n",
    "        \n",
    "        # the matrix from its entries\n",
    "        A22=K3.getMatrix(0,0,N2,N2)\n",
    "        #print(A22,\"A22\")\n",
    "\n",
    "        return A22\n",
    "# Define the exponentiated quadratic \n",
    "def exponentiated_quadratic(xa, xb):\n",
    "    \"\"\"Exponentiated quadratic  with σ=1\"\"\"\n",
    "    # L2 distance (Squared Euclidian)\n",
    "    sq_norm = -0.5 * dist.cdist(xa, xb, 'sqeuclidean')\n",
    "    return np.exp(sq_norm)\n",
    " # Gaussian process posterior\n",
    "def GP(X1, y1, X2, kernel_func):\n",
    "    \"\"\"\n",
    "    Calculate the posterior mean and covariance matrix for y2\n",
    "    based on the corresponding input X2, the observations (y1, X1), \n",
    "    and the prior kernel function.\n",
    "    \"\"\"\n",
    "    # Kernel of the observations\n",
    "    Σ11 = kernel_func(X1, X1)\n",
    "    \n",
    "    # Kernel of observations vs to-predict\n",
    "    Σ12 = kernel_func(X1, X2)\n",
    "    # Solve\n",
    "    solved = scipy.linalg.solve(Σ11, Σ12, assume_a='pos').T\n",
    "    print(\"*****\")\n",
    "    #print(\"splved\",solved)\n",
    "    # Compute posterior mean\n",
    "    μ2 = solved @ y1\n",
    "\n",
    "    # Compute the posterior covariance\n",
    "    Σ22 = kernel_func(X2, X2)\n",
    "    Σ2 = Σ22 - (solved @ Σ12)\n",
    "    #print(\"Σ11\",Σ12,Σ12.shape)\n",
    "    return μ2, Σ2  # mean, covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "be413886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1,X2 (6, 1) (5, 1)\n",
      "x_hodlr (5, 6) \n",
      " y1 (6,) \n",
      " A11 (6, 6) \n",
      " A12 (6, 5) \n",
      " A22 (5, 5)\n",
      "mean using HODLR [ 2.95950151e-04 -2.98028777e-01 -2.53298864e-01  1.41255739e-01\n",
      " -8.15246492e-02]\n",
      "covariance matrix using HODLR [[ 9.99992932e-01  9.03281877e-03 -6.40086471e-04  3.01391907e-09\n",
      "   6.36767365e-07]\n",
      " [ 9.03281877e-03  1.39212250e-01 -7.37882934e-02  4.08709913e-07\n",
      "   8.67479635e-05]\n",
      " [-6.40086471e-04 -7.37882934e-02  3.77289156e-01 -1.48626794e-05\n",
      "  -3.99473150e-03]\n",
      " [ 3.01391907e-09  4.08709913e-07 -1.48626794e-05  3.08174752e-08\n",
      "   2.96391420e-05]\n",
      " [ 6.36767365e-07  8.67479635e-05 -3.99473150e-03  2.96391420e-05\n",
      "   9.75956148e-01]]\n",
      "******\n",
      "*****\n",
      "Mean from scratch [ 2.95950151e-04 -2.98028777e-01 -2.53298864e-01  1.41255739e-01\n",
      " -8.15246492e-02]\n",
      "Covariance matrix from scratch [[ 9.99992932e-01  9.03281877e-03 -6.40086471e-04  3.01391906e-09\n",
      "   6.36767365e-07]\n",
      " [ 9.03281877e-03  1.39212250e-01 -7.37882934e-02  4.08709913e-07\n",
      "   8.67479635e-05]\n",
      " [-6.40086471e-04 -7.37882934e-02  3.77289156e-01 -1.48626794e-05\n",
      "  -3.99473150e-03]\n",
      " [ 3.01391906e-09  4.08709913e-07 -1.48626794e-05  3.08174753e-08\n",
      "   2.96391420e-05]\n",
      " [ 6.36767365e-07  8.67479635e-05 -3.99473150e-03  2.96391420e-05\n",
      "   9.75956148e-01]]\n"
     ]
    }
   ],
   "source": [
    "# Compute the posterior mean and covariance\n",
    "\n",
    "# Define the true function that we want to regress on\n",
    "f_sin = lambda x: (np.sin(x)).flatten()\n",
    "\n",
    "N1 = 6  # Number of points to condition on (training points)\n",
    "N2 = 5  # Number of points in posterior (test points)\n",
    "#ny = 5  # Number of functions that will be sampled from the posterior\n",
    "domain = (-6, 6)\n",
    "\n",
    "# Sample observations (X1, y1) on the function\n",
    "X1 = np.random.uniform(domain[0]+2, domain[1]-2, size=(N1, 1))\n",
    "#print(type(X1))\n",
    "y1 = f_sin(X1)\n",
    "# Predict points at uniform spacing to capture function\n",
    "X2 = np.linspace(domain[0], domain[1], N2).reshape(-1, 1)\n",
    "#print(X2.shape)\n",
    "y2_act=f_sin(X2)\n",
    "# Compute posterior mean and covariance\n",
    "K1 = Kernel1(N1)\n",
    "A11 = K1.GP_hod(X1, y1, X1)\n",
    "K2 = Kernel2(N2)\n",
    "A12 = K2.GP_hod(X1, y1, X2)\n",
    "K3 = Kernel3(N2)\n",
    "A22 = K3.GP_hod(X2, y1, X2)\n",
    "print(\"X1,X2\",X1.shape,X2.shape)\n",
    "#print(\"A11\",A12,A12.shape)\n",
    "eps = 1e-12\n",
    "# If we are assembling a symmetric matrix:\n",
    "is_sym = True\n",
    "# If we know that the matrix is also PD:\n",
    "# By setting the matrix to be symmetric-positive definite, \n",
    "# we trigger the fast symmetric factorization method to be used\n",
    "# In all other cases the fast factorization method is used\n",
    "is_pd = True\n",
    "# Creating the HODLR object:\n",
    "#print(type(A11))\n",
    "M=3\n",
    "T = pyhodlrlib.HODLR(N1, M, eps)\n",
    "T.assemble(K1, 'rookPivoting', is_sym, is_pd)\n",
    "# Factorize elements of the tree:\n",
    "T.factorize()\n",
    "# Solving for x in A x = b:\n",
    "x_hodlr = T.solve(A12)\n",
    "x_hodlr=x_hodlr.T\n",
    "# Compute posterior mean\n",
    "#print(x_hodlr.shape,y1.shape,A12.shape,A22.shape)\n",
    "print(\"x_hodlr\",x_hodlr.shape,'\\n',\"y1\",y1.shape,'\\n',\"A11\",A11.shape,'\\n',\"A12\",A12.shape,'\\n',\"A22\",A22.shape)\n",
    "μ2_hod = x_hodlr @ y1\n",
    "Σ2_hod = A22 - (x_hodlr @ A12)\n",
    "print(\"mean using HODLR\",μ2_hod)\n",
    "print(\"covariance matrix using HODLR\",Σ2_hod)\n",
    "print(\"******\")\n",
    "μ2, Σ2 = GP(X1, y1, X2,exponentiated_quadratic)\n",
    "print(\"Mean from scratch\",μ2)\n",
    "print(\"Covariance matrix from scratch\",Σ2)\n",
    "# Compute the standard deviation at the test points to be plotted\n",
    "σ2 = np.sqrt(np.diag(Σ2))\n",
    "σ2_hod = np.sqrt(np.diag(Σ2_hod))\n",
    "\n",
    "# Draw some samples of the posterior\n",
    "y2 = np.random.multivariate_normal(mean=μ2, cov=Σ2, size=1)\n",
    "y2_hod = np.random.multivariate_normal(mean=μ2_hod, cov=Σ2_hod, size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b988f43e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.91950345, -0.03143034,  0.05368037,  0.141281  ,  0.42639043])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5b980487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.08698606, -0.54251342, -0.09087583,  0.14134053,  0.31898221])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2_hod[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cfee0a6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.2794155 , -0.14112001,  0.        ,  0.14112001, -0.2794155 ])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y2_act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "404fe3e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-6.72781252e-03, -2.26017372e-04,  2.59084614e-03,\n",
       "         2.39385316e-04, -1.81655475e-05,  6.01720781e-03],\n",
       "       [-1.20887212e+00, -3.08153805e-02,  3.61310547e-01,\n",
       "         3.26362461e-02, -2.47540427e-03,  1.69563688e+00],\n",
       "       [-1.18082305e+00,  1.51035440e+00,  1.27309411e+00,\n",
       "        -1.59274969e+00,  1.16430001e-01,  5.97042700e-01],\n",
       "       [ 4.87627852e-06,  7.57401086e-01, -3.74201568e-06,\n",
       "         2.44080464e-01, -1.46734630e-03, -2.75074419e-06],\n",
       "       [ 1.02720180e-03,  4.06444959e+00, -7.83675337e-04,\n",
       "        -4.47964136e+00,  5.37447196e-01, -5.80890715e-04]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_hodlr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "88f9f498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE score is 81853670021895.22\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "mape = mean_absolute_percentage_error(y2_act,y2_hod[0])\n",
    "print('MAPE score is {}'.format(mape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "42e09d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE score is 48350981259797.336\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "mape = mean_absolute_percentage_error(y2_act,y2[0])\n",
    "print('MAPE score is {}'.format(mape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "27e021b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8fd41855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian process posterior\n",
    "# Returning the Gaussian Kernel:\n",
    "import scipy\n",
    "from scipy.spatial import distance as dist\n",
    "class Kernel1(pyhodlrlib.HODLR_Matrix):\n",
    "    def getMatrixEntry(self, i, j):\n",
    "        dist=np.linalg.norm(X1[i] - X1[j])\n",
    "        return np.exp(-0.5*(dist)**2)\n",
    "         \n",
    "    def GP_hod(self,X1, y1, X2):\n",
    "        # What we are doing here is explicitly generating \n",
    "        # the matrix from its entries\n",
    "        A11=K1.getMatrix(0,0,N1,N1)\n",
    "        #print(A11,\"A11\")\n",
    "        return A11\n",
    "class Kernel2(pyhodlrlib.HODLR_Matrix):\n",
    "    def getMatrixEntry(self, i, j):\n",
    "        dist=np.linalg.norm(X1[i] - X2[j])\n",
    "        return np.exp(-0.5*(dist)**2)\n",
    "        \n",
    "    def GP_hod(self,X1, y1, X2):\n",
    "       \n",
    "        # the matrix from its entries\n",
    "        A12=K2.getMatrix(0,0,N1,N2)\n",
    "        #print(A12,\"A12\")\n",
    "        \n",
    "        return A12\n",
    "class Kernel3(pyhodlrlib.HODLR_Matrix):\n",
    "    def getMatrixEntry(self, i, j):\n",
    "        dist=np.linalg.norm(X2[i] - X2[j])\n",
    "        return np.exp(-0.5*(dist)**2)\n",
    "         \n",
    "    def GP_hod(self,X1, y1, X2):\n",
    "        \n",
    "        # the matrix from its entries\n",
    "        A22=K3.getMatrix(0,0,N2,N2)\n",
    "        #print(A22,\"A22\")\n",
    "\n",
    "        return A22\n",
    "# Define the exponentiated quadratic \n",
    "def exponentiated_quadratic(xa, xb):\n",
    "    \"\"\"Exponentiated quadratic  with σ=1\"\"\"\n",
    "    # L2 distance (Squared Euclidian)\n",
    "    sq_norm = -0.5 * dist.cdist(xa, xb, 'sqeuclidean')\n",
    "    return np.exp(sq_norm)\n",
    "def rbf_kernel(X1, X2):\n",
    "    n_samples_X1, n_features = X1.shape\n",
    "    n_samples_X2, _ = X2.shape\n",
    "    kernel_matrix = np.zeros((n_samples_X1, n_samples_X2))\n",
    "\n",
    "    for i in range(n_samples_X1):\n",
    "        for j in range(n_samples_X2):\n",
    "            squared_distance = np.linalg.norm(X1[i] - X2[j])\n",
    "            kernel_matrix[i, j] = np.exp(-0.5* (squared_distance)**2)\n",
    "\n",
    "    return kernel_matrix\n",
    " # Gaussian process posterior\n",
    "def GP(X1, y1, X2, kernel_func):\n",
    "    \"\"\"\n",
    "    Calculate the posterior mean and covariance matrix for y2\n",
    "    based on the corresponding input X2, the observations (y1, X1), \n",
    "    and the prior kernel function.\n",
    "    \"\"\"\n",
    "    # Kernel of the observations\n",
    "    Σ11 = kernel_func(X1, X1)\n",
    "    \n",
    "    # Kernel of observations vs to-predict\n",
    "    Σ12 = kernel_func(X1, X2)\n",
    "    # Solve\n",
    "    solved = scipy.linalg.solve(Σ11, Σ12, assume_a='pos').T\n",
    "    print(\"*****\")\n",
    "    #print(\"splved\",solved)\n",
    "    # Compute posterior mean\n",
    "    μ2 = solved @ y1\n",
    "\n",
    "    # Compute the posterior covariance\n",
    "    Σ22 = kernel_func(X2, X2)\n",
    "    Σ2 = Σ22 - (solved @ Σ12)\n",
    "    #print(\"Σ11\",Σ12,Σ12.shape)\n",
    "    return μ2, Σ2  # mean, covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "71dcf053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1,X2 (3, 3) (2, 3)\n",
      "x_hodlr (2, 3) \n",
      " y1 (3,) \n",
      " A11 (3, 3) \n",
      " A12 (3, 2) \n",
      " A22 (2, 2)\n",
      "mean using HODLR [0.00364147 0.00049364]\n",
      "covariance matrix using HODLR [[ 9.99999168e-01 -1.06932378e-07]\n",
      " [-1.06932378e-07  9.99999985e-01]]\n",
      "******\n",
      "*****\n",
      "Mean from scratch [0.00364147 0.00049364]\n",
      "Covariance matrix from scratch [[ 9.99999168e-01 -1.06932378e-07]\n",
      " [-1.06932378e-07  9.99999985e-01]]\n"
     ]
    }
   ],
   "source": [
    "# Compute the posterior mean and covariance\n",
    "\n",
    "\n",
    "\n",
    "# Sample observations (X1, y1) on the function\n",
    "X1 = np.array([[1,2,3],[2,3,4],[4,5,6]])\n",
    "#print(\"X1\",X1.shape)#.reshape(-1,1)\n",
    "y1 = np.array([2,3,4])\n",
    "#print(\"y1\",y1.shape)\n",
    "\n",
    "# Predict points at uniform spacing to capture function\n",
    "X2 = np.array([[5,7,9],[4,8,3]])\n",
    "print(\"X1,X2\",X1.shape,X2.shape)\n",
    "\n",
    "N1=len(X1)\n",
    "N2=len(X2)\n",
    "# Compute posterior mean and covariance\n",
    "K1 = Kernel1(N1)\n",
    "A11 = K1.GP_hod(X1, y1, X1)\n",
    "#A11=A11.reshape(3,3)\n",
    "K2 = Kernel2(N2)\n",
    "A12 = K2.GP_hod(X1, y1, X2)\n",
    "#A12\n",
    "K3 = Kernel3(N2)\n",
    "A22 = K3.GP_hod(X2, y1, X2)\n",
    "\n",
    "#print(\"A11\",A12,A12.shape)\n",
    "eps = 1e-12\n",
    "# If we are assembling a symmetric matrix:\n",
    "is_sym = True\n",
    "# If we know that the matrix is also PD:\n",
    "# By setting the matrix to be symmetric-positive definite, \n",
    "# we trigger the fast symmetric factorization method to be used\n",
    "# In all other cases the fast factorization method is used\n",
    "is_pd = True\n",
    "# Creating the HODLR object:\n",
    "#print(type(A11))\n",
    "M=3\n",
    "T = pyhodlrlib.HODLR(N1, M, eps)\n",
    "T.assemble(K1, 'rookPivoting', is_sym, is_pd)\n",
    "# Factorize elements of the tree:\n",
    "T.factorize()\n",
    "# Solving for x in A x = b:\n",
    "x_hodlr = T.solve(A12)\n",
    "x_hodlr=x_hodlr.T\n",
    "# Compute posterior mean\n",
    "print(\"x_hodlr\",x_hodlr.shape,'\\n',\"y1\",y1.shape,'\\n',\"A11\",A11.shape,'\\n',\"A12\",A12.shape,'\\n',\"A22\",A22.shape)\n",
    "μ2_hod = x_hodlr @ y1\n",
    "Σ2_hod = A22 - (x_hodlr @ A12)\n",
    "print(\"mean using HODLR\",μ2_hod)\n",
    "print(\"covariance matrix using HODLR\",Σ2_hod)\n",
    "print(\"******\")\n",
    "μ2, Σ2 = GP(X1, y1, X2,rbf_kernel)\n",
    "print(\"Mean from scratch\",μ2)\n",
    "print(\"Covariance matrix from scratch\",Σ2)\n",
    "# Compute the standard deviation at the test points to be plotted\n",
    "σ2 = np.sqrt(np.diag(Σ2))\n",
    "σ2_hod = np.sqrt(np.diag(Σ2_hod))\n",
    "\n",
    "# Draw some samples of the posterior\n",
    "y2 = np.random.multivariate_normal(mean=μ2, cov=Σ2, size=1)\n",
    "y2_hod = np.random.multivariate_normal(mean=μ2_hod, cov=Σ2_hod, size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e856bcd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
